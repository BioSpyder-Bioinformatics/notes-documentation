{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tomorrow:\n",
    "- Make the checker recognise how many blanks in 24,48 (you need to add the controls then). \n",
    "- Make checker recognise how many controls in 96\n",
    "- Make melter add a 48 just in case\n",
    "\n",
    "- Make massive dictionary with all probes to hand out just in case\n",
    "- Melt tables and headers ofc\n",
    "\n",
    "\n",
    "Dictionaries I need:\n",
    "- Sample sheet to fill (24, 48, 96) [x]\n",
    "\n",
    "\n",
    "- For melting\n",
    "    - Headers\n",
    "    - For each plate flavour: dict(well:(Findex, Rindex)) [x]\n",
    "    - F/Rindex to sequence dict(F/Rindex: sequence)\n",
    "    - Rindex to Rindex specific to machinery \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample sheet download \n",
    "*Options*\n",
    "- 24/48/96 wells\n",
    "- Number of plates (up to 8)\n",
    "- Project name\n",
    "- Experiment name\n",
    "- Additional comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed functions\n",
    "\n",
    "- Make sample sheet template\n",
    "    + 24 well plateÂ [ ]\n",
    "    + 48 well plate [ ]\n",
    "    + 96 well plate [x]\n",
    "    + Make it in XLSX with colored cells\n",
    "- Re-import sample sheet template\n",
    "    + The function has to recognise\n",
    "        * If it is a 24/48/96 [ ]\n",
    "        * In case is 96 - how many plates on it [x]\n",
    "    + The function has to enforce\n",
    "        * No bspc bsng [ ]\n",
    "        * So many controls (even in bulk quantities) [ ]\n",
    "- Standardised headers for different NGS machines\n",
    "- Melt tables + melt-concatenate tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24_wells = pd.read_csv('24_well_template_assigned.csv', index_col=0)\n",
    "df_24_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_24_wells = df_24_wells.to_dict()\n",
    "dict_24_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24_wells_new_template = pd.read_csv('24_well_template_assigned_copy.csv', index_col=0)\n",
    "df_24_wells_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_24_wells_new_template = df_24_wells_new_template.to_dict()\n",
    "dict_24_wells_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_48_wells_new_template = pd.read_csv('48_well_template_assigned_copy.csv', index_col=0)\n",
    "df_48_wells_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_48_wells_new_template = df_48_wells_new_template.to_dict()\n",
    "dict_48_wells_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_96_wells_new_template = pd.read_csv('96_well_template_assigned_copy.csv', index_col=0)\n",
    "df_96_wells_new_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_96_wells_new_template = df_96_wells_new_template.to_dict()\n",
    "dict_96_wells_new_template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export sheets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make standard 96 well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_standard_96_well = pd.read_csv('clean_96_template.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_standard_96_well_dict = _standard_96_well.to_dict()\n",
    "_standard_96_well_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardised dictionaries declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_96_dict = {\n",
    "    'R01': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R02': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R03': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R04': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R05': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R06': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R07': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R08': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R09': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R10': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R11': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'},\n",
    "    'R12': {'F01': 'nan',\n",
    "        'F02': 'nan',\n",
    "        'F03': 'nan',\n",
    "        'F04': 'nan',\n",
    "        'F05': 'nan',\n",
    "        'F06': 'nan',\n",
    "        'F07': 'nan',\n",
    "        'F08': 'nan',\n",
    "        'nan': 'nan'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "standard_96_well_table = pd.DataFrame.from_dict(standard_96_dict)\n",
    "standard_96_well_table\n",
    "table_96_well = standard_96_well_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_96_well_sample_sheet(filename, n_plates):\n",
    "    # Load table in df format\n",
    "    #table_96_well = pd.DataFrame.from_dict(table_96_well)\n",
    "\n",
    "    # n_plates has to be 1 < x < 8\n",
    "    if n_plates < 1 or n_plates > 8:\n",
    "        raise Exception('Cannot process that quantity')\n",
    "    \n",
    "    # Check if filename already exists!\n",
    "    if os.path.isfile(filename):\n",
    "        raise Exception('This file already exists') # Make this so the user can decide to overwrite\n",
    "\n",
    "    # Open file once and append tables to it. The file is opened in 'w' so to over-write anything else (anyway you get blocked by the exception above if the file already exists)\n",
    "    with open(filename, 'w') as file:\n",
    "        for _ in range(n_plates):\n",
    "            table_96_well.to_csv(file, mode='a', index=True, header=True)\n",
    "\n",
    "make_96_well_sample_sheet('file.csv', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_24_dict = {\n",
    "    'R01': {\n",
    "        'F01': 'sample',\n",
    "        'F02': 'sample',\n",
    "        'F03': 'sample',\n",
    "        'F04': 'sample',\n",
    "        'F05': 'sample',\n",
    "        'F06': 'sample',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "           },\n",
    "    'R02': {\n",
    "        'F01': 'sample',\n",
    "        'F02': 'sample',\n",
    "        'F03': 'sample',\n",
    "        'F04': 'sample',\n",
    "        'F05': 'sample',\n",
    "        'F06': 'sample',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "              },\n",
    "    'R03': {\n",
    "        'F01': 'sample',\n",
    "        'F02': 'sample',\n",
    "        'F03': 'sample',\n",
    "        'F04': 'sample',\n",
    "        'F05': 'sample',\n",
    "        'F06': 'sample',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "            },\n",
    "    'R04': {\n",
    "        'F01': 'sample',\n",
    "        'F02': 'sample',\n",
    "        'F03': 'sample',\n",
    "        'F04': 'sample',\n",
    "        'F05': 'sample',\n",
    "        'F06': 'sample',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "            },\n",
    "    'R05': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "            },\n",
    "    'NoIndex': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "          },\n",
    "    'NoIndex.1': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'},\n",
    "    'NoIndex.2': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "       },\n",
    "    'NoIndex.3': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "      'NoIndex2': 'blank'\n",
    "     },\n",
    "    'NoIndex.4': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "        },\n",
    "    'NoIndex.5': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "        },\n",
    "    'NoIndex.6': {\n",
    "        'F01': 'blank',\n",
    "        'F02': 'blank',\n",
    "        'F03': 'blank',\n",
    "        'F04': 'blank',\n",
    "        'F05': 'blank',\n",
    "        'F06': 'blank',\n",
    "        'NoIndex1': 'blank',\n",
    "        'NoIndex2': 'blank'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "different_48_dict = {'R01': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R02': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R03': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R04': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R05': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R06': {'F01': 'sample',\n",
    "  'F02': 'sample',\n",
    "  'F03': 'sample',\n",
    "  'F04': 'sample',\n",
    "  'F05': 'sample',\n",
    "  'F06': 'sample',\n",
    "  'F07': 'sample',\n",
    "  'F08': 'sample'},\n",
    " 'R07': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'},\n",
    " 'NoIndex': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'},\n",
    " 'NoIndex.1': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'},\n",
    " 'NoIndex.2': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'},\n",
    " 'NoIndex.3': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'},\n",
    " 'NoIndex.4': {'F01': 'blank',\n",
    "  'F02': 'blank',\n",
    "  'F03': 'blank',\n",
    "  'F04': 'blank',\n",
    "  'F05': 'blank',\n",
    "  'F06': 'blank',\n",
    "  'F07': 'blank',\n",
    "  'F08': 'blank'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make 24 and 48 well plate sample sheet\n",
    "def make_24_48_well_sample_sheet(filename, twentyfour):\n",
    "    # Check if filename already exists!\n",
    "    if os.path.isfile(filename):\n",
    "        raise Exception('This file already exists') # Make this so the user can decide to overwrite\n",
    "    \n",
    "    #If true it's for the 24, if false it's for the 48\n",
    "    if twentyfour:\n",
    "        write = different_24_dict\n",
    "    else:\n",
    "        write = different_48_dict\n",
    "    \n",
    "    # Convert dictionary to pd data frame\n",
    "    table_to_write = pd.DataFrame.from_dict(write)\n",
    "    \n",
    "    with open(filename, 'w') as file:\n",
    "        table_to_write.to_csv(file, mode='w', index=True, header=True)\n",
    "        \n",
    "    \n",
    "make_24_48_well_sample_sheet('48_wells.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make 96 well plate sample sheet based on number of plates\n",
    "def make_96_well_sample_sheet(filename, n_plates):\n",
    "    # n_plates has to be 1 < x < 8\n",
    "    if n_plates < 1 or n_plates > 8:\n",
    "        raise Exception('Cannot process that quantity')\n",
    "    \n",
    "    # Check if filename already exists!\n",
    "    if os.path.isfile(filename):\n",
    "        raise Exception('This file already exists') # Make this so the user can decide to overwrite\n",
    "\n",
    "\n",
    "    # Processes to obtain the standard_96_well_table (eg 2 cells above) will be included in the function, not done here for practicality\n",
    "    with open(filename, 'w') as file:\n",
    "        for _ in range(n_plates):\n",
    "        # Both solutions work, probably better doing the with open as it opens the file only once (remove it if using straight to csv)\n",
    "        #standard_96_well_table.to_csv(filename, mode='a', index=True, header=True)\n",
    "\n",
    "            standard_96_well_table.to_csv(file, mode='a', index=True, header=True)\n",
    "\n",
    "\n",
    "make_96_well_sample_sheet('new_csv.csv', 3)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 96 well plates \n",
    "\n",
    "# Just a try to see how it reads it in with 4 whole plates\n",
    "df_96_wells_4_plates = pd.read_csv('96_well_template_4_plates.csv', index_col=0)\n",
    "df_96_wells_4_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For when you're reading it in, i'd probably check the length of the DF, in case is > 8 split\n",
    "df_len = len(df_96_wells_4_plates)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Slice the imported DF so that the 9th and 10th lines are skipped and append them to an array\n",
    "for x in range(8, df_len+1, 10):\n",
    "    low_end = 0 if x == 8 else x - 8\n",
    "    dfs.append(df_96_wells_4_plates.iloc[low_end:x, :])\n",
    "\n",
    "\n",
    "for m in dfs:\n",
    "    print(m)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import single tables from a single/multiple sample sheet (already read in)\n",
    "def get_tables(sample_sheet):\n",
    "    # Number of rows in sample sheet\n",
    "    df_len = len(sample_sheet)\n",
    "    #dfs to be\n",
    "    dfs = []\n",
    "    # Slice the sample sheet so that the recurring 10th line gets skipped (the empty one)\n",
    "    for x in range(8, df_len+1, 10):\n",
    "        low_end = 0 if x == 8 else x - 8\n",
    "        dfs.append(sample_sheet.iloc[low_end:x, :])\n",
    "    return dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = get_tables(df_96_wells_4_plates)\n",
    "len(tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim and melt table - 96 well plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_96_well_table\n",
    "standard_96_well_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim table function\n",
    "def trim_table(table):\n",
    "    return table[table.index != 'nan']\n",
    "\n",
    "# trimmed_table = trim_table(standard_96_well_table)\n",
    "# trimmed_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to be melted\n",
    "to_melt = trim_table(dfs[0])\n",
    "\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make massive sample sheet with all indexes \n",
    "- Make plates primers layout\n",
    "- Make primers dictionary\n",
    "- Make 96-well plate dictionary\n",
    "- Get specific rows required\n",
    "- Make spreadsheet with all plates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plates primer layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primers_from_csv = pd.read_csv('900_series_PCR_primer_plate_layouts.csv', header=None)\n",
    "primers_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the imported DF so to have separate tables\n",
    "len_df = len(primers_from_csv)\n",
    "\n",
    "primer_plates = []\n",
    "\n",
    "for x in range(11, len_df+10, 11):\n",
    "    low_end = 0 if x == 11 else x - 11\n",
    "    # print(low_end, x)\n",
    "    primer_plates.append(primers_from_csv.iloc[low_end:x, :])\n",
    "\n",
    "primer_plates[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_plate_e = primer_plates[0]\n",
    "\n",
    "\n",
    "# single_plate_e = single_plate_e.iloc[1:10, 1:]\n",
    "\n",
    "# header_row = list(single_plate_e.iloc[:1, :-1])\n",
    "# header_index = single_plate_e.iloc[1:,:1].T.values[0]\n",
    "\n",
    "\n",
    "# single_plate_e = single_plate_e.iloc[1:, 1:]\n",
    "\n",
    "# # single_plate_e = pd.DataFrame(single_plate_e.values[1:], columns=header_row, index=header_col)\n",
    "# # single_plate_e = pd.DataFrame(single_plate_e.iloc[1:, 1:], columns=header_row, index=header_col)\n",
    "\n",
    "# single_plate_e.columns = header_row\n",
    "# single_plate_e.index = header_index\n",
    "\n",
    "# single_plate_e_slow = single_plate_e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_plate_e = primer_plates[0]\n",
    "\n",
    "\n",
    "# header_row = list(single_plate_e.iloc[1, 2:])\n",
    "# header_index = single_plate_e.iloc[2:-1,1:2].T.values[0]\n",
    "\n",
    "\n",
    "# single_plate_e = single_plate_e.iloc[2:10, 2:]\n",
    "\n",
    "# single_plate_e.columns = header_row\n",
    "# single_plate_e.index = header_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE CLEAN PLATE FROM THE PRIMER PLATES LAYOUTS\n",
    "\n",
    "def get_clean_plate(plate):\n",
    "    # Get flavour \n",
    "    flavour = plate.iloc[:1, :1].values.tolist()[0][0]\n",
    "    # print(flavour)\n",
    "\n",
    "    #remove table bottom row if null\n",
    "    # table = table[table.index != 'nan']\n",
    "\n",
    "    # Get row names\n",
    "    header_row = list(plate.iloc[1, 2:])\n",
    "    # Get column names\n",
    "    header_index = plate.iloc[2:10,1:2].T.values[0]\n",
    "\n",
    "    # Remove excess from table\n",
    "    plate = plate.iloc[2:10, 2:]\n",
    "\n",
    "    # Set row and column names\n",
    "    plate.columns = header_row\n",
    "    plate.index = header_index\n",
    "\n",
    "\n",
    "    return (flavour, plate)\n",
    "\n",
    "\n",
    "get_clean_plate(primer_plates[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary with all plates\n",
    "\n",
    "layouts = [get_clean_plate(x) for x in primer_plates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layouts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â The tables obtained in this function can be melted, or we can do the dictionary as done below and use it to check if it is corret as a kind of enforcement check just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_plate_e = get_clean_plate(primer_plates[1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_plate_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in clean_plate_e:\n",
    "    print(clean_plate_e[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "plate_e_dict={}\n",
    "# Hyper loop to go through all the table \n",
    "for column in clean_plate_e:\n",
    "    for row in clean_plate_e[column].keys():\n",
    "        cell = clean_plate_e[column][row]\n",
    "        f_primer = re.findall(r'F\\d{3}', cell)[0]\n",
    "        r_primer = re.findall(r'R\\d{3}', cell)[0]\n",
    "        plate_e_dict[f'{row}{int(column):02d}'] = (f_primer, r_primer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_e_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# GET DICTIONARY of PRIMERS FROM CLEAN TABLE\n",
    "\n",
    "def make_dictionary_for_primers(plate, flavour):\n",
    "    dictionary = {}\n",
    "    for column in plate:\n",
    "        for row in plate[column].keys():\n",
    "            cell = plate[column][row]\n",
    "            f_primer = re.findall(r'F\\d{3}', cell)[0]\n",
    "            r_primer = re.findall(r'R\\d{3}', cell)[0]\n",
    "            dictionary[f'{row}{int(column):02d}'] = (f_primer, r_primer, flavour)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow to make plates dictionaries\n",
    "# E F G H I J K L\n",
    "# 0 1 2 3 4 5 6 7\n",
    "\n",
    "#primer_plates\n",
    "\n",
    "table = get_clean_plate(primer_plates[7])\n",
    "dictionary = make_dictionary_for_primers(table)\n",
    "\n",
    "dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOOOO WE HAVE ALL LAYOUTS\n",
    "\n",
    "\n",
    "layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the dictionaries for them\n",
    "\n",
    "dictionaries_all_layouts = [make_dictionary_for_primers(x[1], x[0]) for x in layouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_all_layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_all_layouts = [pd.DataFrame.from_dict(x, orient='index', columns=[ 'I5_Index_ID', 'I7_Index_ID', 'Sample_Plate']) for x in dictionaries_all_layouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_layouts # Sample_Well index\n",
    "\n",
    "#Put index\n",
    "df_all_layouts = [df.rename_axis('Sample_Well').reset_index(level=0) for df in df_all_layouts]\n",
    "\n",
    "df_all_layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all layouts\n",
    "df_all_layouts_merged = pd.concat([table for table in df_all_layouts]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_layouts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionaries import *\n",
    "# Now add the sequences to the indexes\n",
    "\n",
    "df = df_all_layouts_merged\n",
    "\n",
    "df['index'] = df['I7_Index_ID'].map(r_primers_to_sequence)\n",
    "\n",
    "#If next seq map to other dict\n",
    "\n",
    "df['index2_reverse'] = df['I5_Index_ID'].map(f_primers_to_reverse_complement) #!!!!!! ONLY FOR NEXTSEQ\n",
    "df['index2'] = df['I5_Index_ID'].map(f_primers_to_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create baseline sample sheet\n",
    "# need\n",
    "#\"Sample_ID\",\"Sample_Name\",\"Sample_Project\",\"Description\"\n",
    "\n",
    "df['Sample_Name'] = [f'__Plate_{y}_{x}' for x,y in zip(df['Sample_Well'], df['Sample_Plate'])]\n",
    "\n",
    "# Add Sample_Project and Description rows (empty rows)\n",
    "df['Sample_Project'], df['Description']  = np.nan, np.nan\n",
    "\n",
    "df['Sample_ID'] = df.index +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Sample_ID', 'Sample_Name', 'Sample_Plate', 'Sample_Well', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project', 'Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_layouts_all_flavours_master_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionaries import complete_sample_sheet_string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "new_df = pd.read_csv(StringIO(complete_sample_sheet_string), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OKKKK \n",
    "# Now you have the complete sample sheet, make function to map sample names to sample well and one to filter out any rows that start with __ and youre ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual making of plate E dictionary, used to cross-check the function declared above \n",
    "\n",
    "\n",
    "columns = ['R902',\t'R908',\t'R911',\t'R912',\t'R913',\t'R919',\t'R920',\t'R921',\t'R922',\t'R923',\t'R924',\t'R935']\n",
    "columns_number = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "cols_zip = list(zip(columns_number, columns))\n",
    "\n",
    "rows = ['F904', 'F906', 'F908', 'F916', 'F927', 'F934', 'F935', 'F936']\n",
    "rows_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "\n",
    "rows_zip = list(zip(rows_letters, rows))\n",
    "\n",
    "plate_e_layout = {}\n",
    "\n",
    "\n",
    "for x in range(len(cols_zip)):\n",
    "    for y in range(len(rows_zip)):\n",
    "        # print(f'{rows_zip[y][0]}{cols_zip[x][0]:02d}', (rows_zip[y][1], cols_zip[x][1]))\n",
    "        plate_e_layout[f'{rows_zip[y][0]}{cols_zip[x][0]:02d}'] = (rows_zip[y][1], cols_zip[x][1])\n",
    "\n",
    "plate_e_layout        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if manually produced dictionary is the same as the one made automatically\n",
    "for key in plate_e_dict.keys():\n",
    "    if (plate_e_dict[key] != plate_e_layout[key]):\n",
    "        print('NOPE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes to sequence dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_primers = pd.read_csv('Index_Sequences_900_Series_Primers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_r_primers = table_of_primers.iloc[:,:2]\n",
    "table_r_primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_primers_dict={}\n",
    "for index, row in table_r_primers.iterrows():\n",
    "    if row['i7_R_name'] not in r_primers_dict:\n",
    "        r_primers_dict[row['i7_R_name']] = row['i7_Seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_primers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_f_primers = table_of_primers.iloc[:,3:6]\n",
    "\n",
    "table_f_primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_primers_dict = {}\n",
    "for index, row in table_f_primers.iterrows():\n",
    "    if row['i5_F_name'] not in f_primers_dict:\n",
    "        f_primers_dict[row['i5_F_name']] = row['i5_Seq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_primers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_primers_reverse_dict = {}\n",
    "\n",
    "for index, row in table_f_primers.iterrows():\n",
    "    if row['i5_F_name'] not in f_primers_reverse_dict:\n",
    "        f_primers_reverse_dict[row['i5_F_name']] = row['i5_Reverse_complement_seq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_primers_reverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries for headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Column names per machine\n",
    "hi_seq_cols = ['Sample_ID', 'Sample_Name', 'Sample_Plate', 'Sample_Well', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project', 'Description'] #Â Sample_Project and Description are empty\n",
    "\n",
    "mini_seq_cols = ['Sample_ID', 'Description', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project'] # Description and Sample_Project are empty (ONLY ONE DIFFERENT + THE ONE WITH FOLDER) (Minus Sample_Name, Sample_Plate, Sample_Well, Description)\n",
    "\n",
    "mi_seq_cols = ['Sample_ID', 'Sample_Name', 'Sample_Plate', 'Sample_Well', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project', 'Description'] #Â Sample_Project and Description are empty (IDENTICAL TO HISEQ)\n",
    "\n",
    "next_seq_cols = ['Sample_ID', 'Sample_Name', 'Sample_Plate', 'Sample_Well', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project', 'Description'] #Â Sample_Project and Description are empty (IDENTICAL TO HISEQ and MISEQ) (((!!!This is the one that needs the reverse complement!!!)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Headers\n",
    "hi_seq_header = {} #none\n",
    "\n",
    "mini_seq_header = {}\n",
    "\n",
    "mi_seq_header = {}\n",
    "\n",
    "next_seq_header = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract miniseq\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def make_miniseq_header(experiment_name):\n",
    "    date = datetime.today().strftime('%m/%d/%Y')\n",
    "    text = f'''[Header],,,,,,\n",
    "    Experiment Name,{experiment_name},,,,,\n",
    "    Date,{date},,,,,\n",
    "    Module,GenerateFASTQ - 2.0.1,,,,,\n",
    "    Workflow,GenerateFASTQ,,,,,\n",
    "    Library Prep Kit,BioSpyder900,,,,,\n",
    "    Chemistry,Amplicon,,,,,\n",
    "    [Reads],,,,,,\n",
    "    50,,,,,,\n",
    "    [Settings],,,,,,\n",
    "    adapter,CTGTCTCTTATACACATCT,,,,,\n",
    "    [Data],,,,,,\n",
    "    Sample_ID,Description,I7_Index_ID,index,I5_Index_ID,index2,Sample_Project\n",
    "    '''\n",
    "    return text\n",
    "\n",
    "make_miniseq_header('x')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def make_miseq_header(project_name, experiment_name, comments):\n",
    "    date = datetime.today().strftime('%m/%d/%Y')\n",
    "    text = f'''\"[Header]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"IEMFileVersion\",\"4\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Investigator\",\"BioSpyder\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Project Name\",\"{project_name}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Experiment Name\",\"{experiment_name}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Date\",\"{date}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Workflow\",\"GenerateFASTQ\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Application\",\"FASTQ Only\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Assay\",\"Nextera\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Description\",\"MiSeq\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Chemistry\",\"Amplicon\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Additional Comments\",\"{comments}\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
    "    \"[Manifests]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Reads]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"50\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Settings]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"CustomIndexPrimerMix\",\"C2\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Data]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Sample_ID\",\"Sample_Name\",\"Sample_Plate\",\"Sample_Well\",\"I7_Index_ID\",\"index\",\"I5_Index_ID\",\"index2\",\"Sample_Project\",\"Description\"\n",
    "    '''\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "print(make_miseq_header('PROJECT', 'EXPERIMENT', 'COMMENT'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def make_nextseq_header(project_name, experiment_name, comments):\n",
    "    date = datetime.today().strftime('%m/%d/%Y')\n",
    "    text = f'''\"[Header]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"IEMFileVersion\",\"4\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Investigator\",\"BioSpyder\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Project Name\",\"{project_name}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Experiment Name\",\"{experiment_name}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Date\",\"{date}\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Workflow\",\"GenerateFASTQ\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Application\",\"NextSeq FASTQ Only\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Assay\",\"Nextera\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Description\",\"NextSeq\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Chemistry\",\"Amplicon\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Additional Comments\",\"{comments}\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
    "    \"[Manifests]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Reads]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"50\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Settings]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"CustomIndexPrimerMix\",\"C2\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"[Data]\",\"\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\n",
    "    \"Sample_ID\",\"Sample_Name\",\"Sample_Plate\",\"Sample_Well\",\"I7_Index_ID\",\"index\",\"I5_Index_ID\",\"index2\",\"Sample_Project\",\"Description\"'''\n",
    "    return text\n",
    "\n",
    "make_nextseq_header('PROJECT', 'EXPERIMENT', 'COMMENT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COOOL Now melt the tables by making series of the columns (or dictionaries instead of series so you have arrays) and match them with the associated dictionaries to create rows. Maybe a lambda function per column so to extract automatically?? you're there, then remember to compare the raw text of the sample sheets with the one produced from these functions.\n",
    "- Make enclosing function that based on parameters calls the inner functions to structure a final writable string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we need in final dictionary\n",
    "*Get as input*\n",
    "- Sample_Name -> Name given by the user\n",
    "- Sample_Plate -> Plate flavour (chosen by the user)\n",
    "\n",
    "*Need function, map it to the sample names*\n",
    "- Sample_Well -> Position in plate (eg A01-H12)\n",
    "\n",
    "*These are dependent on the Sample_Well and Sample_Plate*\n",
    "- I7_Index_ID -> Id eg Rxxx\n",
    "- index -> Index nucleotide sequence\n",
    "- I5_Index_ID -> Id eg Fxxx\n",
    "- index2 -> index nucleotide sequence\n",
    "\n",
    "*Independent*\n",
    "- Sample_ID -> Sequential index\n",
    "\n",
    "*Empty*\n",
    "- Sample_Project -> empty\n",
    "- Description -> empty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soo thinking about the dictionary concatenation\n",
    "*From the sample sheet you import*\n",
    "- R01/F01 -> Sample name\n",
    "\n",
    "*From this we do*\n",
    "- R01/F01 -> Well position (eg A01,B05..)\n",
    "\n",
    "*Get index dictionaries based on the sample plate*\n",
    "- Append Sample_Plate\n",
    "\n",
    "*Based on sample plate and well position*\n",
    "- I7-I5 indexes\n",
    "\n",
    "*Append sample_id (reset indexes)*\n",
    "\n",
    "Append the rest (sample project and description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On reupload, read the table and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_plate = tables[0]\n",
    "single_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_map = tables[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get df with sample_name->sample_well from DF table \n",
    "\n",
    "plate_wells_mapping = single_plate.to_dict()\n",
    "\n",
    "\n",
    "# Starting variable\n",
    "mapped_plate = pd.DataFrame.from_dict(plate_wells_mapping)\n",
    "mapped_plate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapped_plate.shape, to_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â This is just for development purposes\n",
    "plate_i_layout = {'A01': ('F910', 'R902'),\n",
    " 'B01': ('F913', 'R902'),\n",
    " 'C01': ('F914', 'R902'),\n",
    " 'D01': ('F915', 'R902'),\n",
    " 'E01': ('F923', 'R902'),\n",
    " 'F01': ('F928', 'R902'),\n",
    " 'G01': ('F930', 'R902'),\n",
    " 'H01': ('F933', 'R902'),\n",
    " 'A02': ('F910', 'R908'),\n",
    " 'B02': ('F913', 'R908'),\n",
    " 'C02': ('F914', 'R908'),\n",
    " 'D02': ('F915', 'R908'),\n",
    " 'E02': ('F923', 'R908'),\n",
    " 'F02': ('F928', 'R908'),\n",
    " 'G02': ('F930', 'R908'),\n",
    " 'H02': ('F933', 'R908'),\n",
    " 'A03': ('F910', 'R911'),\n",
    " 'B03': ('F913', 'R911'),\n",
    " 'C03': ('F914', 'R911'),\n",
    " 'D03': ('F915', 'R911'),\n",
    " 'E03': ('F923', 'R911'),\n",
    " 'F03': ('F928', 'R911'),\n",
    " 'G03': ('F930', 'R911'),\n",
    " 'H03': ('F933', 'R911'),\n",
    " 'A04': ('F910', 'R912'),\n",
    " 'B04': ('F913', 'R912'),\n",
    " 'C04': ('F914', 'R912'),\n",
    " 'D04': ('F915', 'R912'),\n",
    " 'E04': ('F923', 'R912'),\n",
    " 'F04': ('F928', 'R912'),\n",
    " 'G04': ('F930', 'R912'),\n",
    " 'H04': ('F933', 'R912'),\n",
    " 'A05': ('F910', 'R913'),\n",
    " 'B05': ('F913', 'R913'),\n",
    " 'C05': ('F914', 'R913'),\n",
    " 'D05': ('F915', 'R913'),\n",
    " 'E05': ('F923', 'R913'),\n",
    " 'F05': ('F928', 'R913'),\n",
    " 'G05': ('F930', 'R913'),\n",
    " 'H05': ('F933', 'R913'),\n",
    " 'A06': ('F910', 'R919'),\n",
    " 'B06': ('F913', 'R919'),\n",
    " 'C06': ('F914', 'R919'),\n",
    " 'D06': ('F915', 'R919'),\n",
    " 'E06': ('F923', 'R919'),\n",
    " 'F06': ('F928', 'R919'),\n",
    " 'G06': ('F930', 'R919'),\n",
    " 'H06': ('F933', 'R919'),\n",
    " 'A07': ('F910', 'R920'),\n",
    " 'B07': ('F913', 'R920'),\n",
    " 'C07': ('F914', 'R920'),\n",
    " 'D07': ('F915', 'R920'),\n",
    " 'E07': ('F923', 'R920'),\n",
    " 'F07': ('F928', 'R920'),\n",
    " 'G07': ('F930', 'R920'),\n",
    " 'H07': ('F933', 'R920'),\n",
    " 'A08': ('F910', 'R921'),\n",
    " 'B08': ('F913', 'R921'),\n",
    " 'C08': ('F914', 'R921'),\n",
    " 'D08': ('F915', 'R921'),\n",
    " 'E08': ('F923', 'R921'),\n",
    " 'F08': ('F928', 'R921'),\n",
    " 'G08': ('F930', 'R921'),\n",
    " 'H08': ('F933', 'R921'),\n",
    " 'A09': ('F910', 'R922'),\n",
    " 'B09': ('F913', 'R922'),\n",
    " 'C09': ('F914', 'R922'),\n",
    " 'D09': ('F915', 'R922'),\n",
    " 'E09': ('F923', 'R922'),\n",
    " 'F09': ('F928', 'R922'),\n",
    " 'G09': ('F930', 'R922'),\n",
    " 'H09': ('F933', 'R922'),\n",
    " 'A10': ('F910', 'R923'),\n",
    " 'B10': ('F913', 'R923'),\n",
    " 'C10': ('F914', 'R923'),\n",
    " 'D10': ('F915', 'R923'),\n",
    " 'E10': ('F923', 'R923'),\n",
    " 'F10': ('F928', 'R923'),\n",
    " 'G10': ('F930', 'R923'),\n",
    " 'H10': ('F933', 'R923'),\n",
    " 'A11': ('F910', 'R924'),\n",
    " 'B11': ('F913', 'R924'),\n",
    " 'C11': ('F914', 'R924'),\n",
    " 'D11': ('F915', 'R924'),\n",
    " 'E11': ('F923', 'R924'),\n",
    " 'F11': ('F928', 'R924'),\n",
    " 'G11': ('F930', 'R924'),\n",
    " 'H11': ('F933', 'R924'),\n",
    " 'A12': ('F910', 'R935'),\n",
    " 'B12': ('F913', 'R935'),\n",
    " 'C12': ('F914', 'R935'),\n",
    " 'D12': ('F915', 'R935'),\n",
    " 'E12': ('F923', 'R935'),\n",
    " 'F12': ('F928', 'R935'),\n",
    " 'G12': ('F930', 'R935'),\n",
    " 'H12': ('F933', 'R935')}\n",
    "\n",
    "flavours_list = {\n",
    "    'I':plate_i_layout,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_primers_to_sequence = {'R901': 'GTATTATTG',\n",
    " 'R902': 'TCCTCAGCC',\n",
    " 'R903': 'TAACGCGTC',\n",
    " 'R904': 'AACACGTCT',\n",
    " 'R905': 'AGATAGCCT',\n",
    " 'R906': 'TCCAGTATC',\n",
    " 'R907': 'AAGGATACC',\n",
    " 'R908': 'AAGACTCTT',\n",
    " 'R909': 'AGGATCTGG',\n",
    " 'R910': 'GCAGATGCA',\n",
    " 'R911': 'GGGTTGTTA',\n",
    " 'R912': 'GAACTGTAT',\n",
    " 'R913': 'GTTTATACT',\n",
    " 'R914': 'GGGCAGATC',\n",
    " 'R915': 'ACCATTCAA',\n",
    " 'R916': 'GCGATGATT',\n",
    " 'R917': 'TCGTGCGTT',\n",
    " 'R918': 'GCCACCGAA',\n",
    " 'R919': 'ACTCATGTA',\n",
    " 'R920': 'ATTCGCTCT',\n",
    " 'R921': 'TCAGTACAT',\n",
    " 'R922': 'TAAGGTAGC',\n",
    " 'R923': 'TGCATGACA',\n",
    " 'R924': 'GACTTCATT',\n",
    " 'R925': 'GCTGTAGTT',\n",
    " 'R926': 'ATGAGTTCC',\n",
    " 'R927': 'GTGATCTGA',\n",
    " 'R928': 'ATGTGTGCT',\n",
    " 'R929': 'GGAATGCAT',\n",
    " 'R930': 'TCGCCACTC',\n",
    " 'R931': 'GCATGGACC',\n",
    " 'R932': 'TAATGGCTT',\n",
    " 'R933': 'TCCTTCGTG',\n",
    " 'R934': 'TATCGCTCC',\n",
    " 'R935': 'TAGCTCTTC',\n",
    " 'R936': 'TGGAACGCT',\n",
    " 'R937': 'ATCGCGACT',\n",
    " 'R938': 'ATTCGAATC',\n",
    " 'R939': 'TTCCGCACC',\n",
    " 'R940': 'GGCAGACTT',\n",
    " 'R941': 'GCGATAGTG',\n",
    " 'R942': 'ATTGTTGCC',\n",
    " 'R943': 'TGCTTATTC',\n",
    " 'R944': 'ACACGTTAT',\n",
    " 'R945': 'TCAGCTAAT',\n",
    " 'R946': 'TGATTAAGC',\n",
    " 'R947': 'GTAGCTCCA',\n",
    " 'R948': 'GAATTGCTG',\n",
    " 'R949': 'GATCCGGTT',\n",
    " 'R950': 'ATACCGGCA',\n",
    " 'R951': 'ATTGGTTGC',\n",
    " 'R952': 'TCCGCGGAT',\n",
    " 'R953': 'GTGTATCCG',\n",
    " 'R954': 'ACAGCTCTA',\n",
    " 'R955': 'GGTAGACCA',\n",
    " 'R956': 'ACTAGCCTG',\n",
    " 'R957': 'ACCTCTTCA',\n",
    " 'R958': 'GAAGGCTGC',\n",
    " 'R959': 'GCTATCGAT',\n",
    " 'R960': 'ACTGGACCG',\n",
    " 'R961': 'GTGAGCCTA',\n",
    " 'R962': 'TTCTATAAA',\n",
    " 'R963': 'TATTAACTG',\n",
    " 'R964': 'AGCATATCA',\n",
    " 'R965': 'GAGCTATGC',\n",
    " 'R966': 'AGGTAGTCG',\n",
    " 'R967': 'AAATCTACG',\n",
    " 'R968': 'TGGTTACTA',\n",
    " 'R969': 'GCAGCAACA',\n",
    " 'R970': 'ATACGGATG',\n",
    " 'R971': 'GAATCCGCA',\n",
    " 'R972': 'AATGGCGGC',\n",
    " 'R973': 'TTGTAATCG',\n",
    " 'R974': 'AATGCCACG',\n",
    " 'R975': 'TCAGACATA',\n",
    " 'R976': 'GCTATGCAA',\n",
    " 'R977': 'TGAGTCATG',\n",
    " 'R978': 'GGAGGAGCA',\n",
    " 'R979': 'GAACTTGGA',\n",
    " 'R980': 'TTCTCTGCG',\n",
    " 'R981': 'AGTAGAACG',\n",
    " 'R982': 'AGACTTCGA',\n",
    " 'R983': 'TAGCGACAA',\n",
    " 'R984': 'ATATGCCGG',\n",
    " 'R985': 'GCTTCTGAA',\n",
    " 'R986': 'ACCTGAGGC',\n",
    " 'R987': 'TTGGACGCG',\n",
    " 'R988': 'AGTACTAGA',\n",
    " 'R989': 'ACGAGACGG',\n",
    " 'R990': 'AGCCGATTA',\n",
    " 'R991': 'AGTGTGAGA',\n",
    " 'R992': 'TCCAACAGG',\n",
    " 'R993': 'ATCTGCGTA',\n",
    " 'R994': 'ACCTTAAGG',\n",
    " 'R995': 'GTGGCGGAA',\n",
    " 'R996': 'GATAGCGGA'}\n",
    "\n",
    "\n",
    "f_primers_to_sequence = {'F901': 'AACTACAGC',\n",
    " 'F902': 'TTCTGGGCA',\n",
    " 'F903': 'GCACACTGT',\n",
    " 'F904': 'CTAATGCAC',\n",
    " 'F905': 'AGGTAACAT',\n",
    " 'F906': 'GATGGTTGT',\n",
    " 'F907': 'GGTCCATGC',\n",
    " 'F908': 'AAGGTGTTT',\n",
    " 'F909': 'CCATCAGCC',\n",
    " 'F910': 'GGACTAAGA',\n",
    " 'F911': 'TCATTGAAA',\n",
    " 'F912': 'AGACGTGTT',\n",
    " 'F913': 'CGTAGATTT',\n",
    " 'F914': 'GCTCAGCTT',\n",
    " 'F915': 'GGTATCCTT',\n",
    " 'F916': 'AATTCGGAA',\n",
    " 'F917': 'CAACACGCA',\n",
    " 'F918': 'GGCCTGTCA',\n",
    " 'F919': 'GAACCAATT',\n",
    " 'F920': 'AGAACCATA',\n",
    " 'F921': 'AGGCTATCT',\n",
    " 'F922': 'GAGACCACC',\n",
    " 'F923': 'GGTTAAGGC',\n",
    " 'F924': 'CAGTTAATA',\n",
    " 'F925': 'CACAGGCCA',\n",
    " 'F926': 'TGACGGCCA',\n",
    " 'F927': 'GACCTTGCT',\n",
    " 'F928': 'AGATTGAGT',\n",
    " 'F929': 'AGGAGTCCA',\n",
    " 'F930': 'GCGATAGCA',\n",
    " 'F931': 'TGGCAAGGT',\n",
    " 'F932': 'CATAGCATA',\n",
    " 'F933': 'CCAAGTCGT',\n",
    " 'F934': 'TGCATCTGC',\n",
    " 'F935': 'GACGCGTTA',\n",
    " 'F936': 'AGCCTACTT',\n",
    " 'F937': 'ATGGTTAGA',\n",
    " 'F938': 'GCTGCGTAT',\n",
    " 'F939': 'TGTAACGGC',\n",
    " 'F940': 'AATAGGTGC',\n",
    " 'F941': 'AACACAATC',\n",
    " 'F942': 'TGCCGGTAT',\n",
    " 'F943': 'TAAGTTACG',\n",
    " 'F944': 'AGCTAGACC',\n",
    " 'F945': 'ATTGTGTCT',\n",
    " 'F946': 'TAGCGTCAA',\n",
    " 'F947': 'TGTGAGCAT',\n",
    " 'F948': 'CAGAACCTA',\n",
    " 'F949': 'TTAGGACTT',\n",
    " 'F950': 'GCCATGCTC',\n",
    " 'F951': 'ATACAGTTC',\n",
    " 'F952': 'TATACGCTT',\n",
    " 'F953': 'TTGGATTCA',\n",
    " 'F954': 'CCGATGTTC',\n",
    " 'F955': 'TTCGGTGGC',\n",
    " 'F956': 'TCAGATCAC',\n",
    " 'F957': 'ATAGCACAA',\n",
    " 'F958': 'TCGCTACGC',\n",
    " 'F959': 'CCTCTGGTT',\n",
    " 'F960': 'TCCTCACGC',\n",
    " 'F961': 'CGAGAGGTA',\n",
    " 'F962': 'TCTGTCATT',\n",
    " 'F963': 'CGCCAGTCT',\n",
    " 'F964': 'CGCTACAAC'}\n",
    "\n",
    "\n",
    "\n",
    "f_primers_to_reverse_complement = {'F901': 'GCTGTAGTT',\n",
    " 'F902': 'TGCCCAGAA',\n",
    " 'F903': 'ACAGTGTGC',\n",
    " 'F904': 'GTGCATTAG',\n",
    " 'F905': 'ATGTTACCT',\n",
    " 'F906': 'ACAACCATC',\n",
    " 'F907': 'GCATGGACC',\n",
    " 'F908': 'AAACACCTT',\n",
    " 'F909': 'GGCTGATGG',\n",
    " 'F910': 'TCTTAGTCC',\n",
    " 'F911': 'TTTCAATGA',\n",
    " 'F912': 'AACACGTCT',\n",
    " 'F913': 'AAATCTACG', ####################################\n",
    " 'F914': 'AAGCTGAGC',\n",
    " 'F915': 'AAGGATACC',\n",
    " 'F916': 'TTCCGAATT',\n",
    " 'F917': 'TGCGTGTTG',\n",
    " 'F918': 'TGACAGGCC',\n",
    " 'F919': 'AATTGGTTC',\n",
    " 'F920': 'TATGGTTCT',\n",
    " 'F921': 'AGATAGCCT',\n",
    " 'F922': 'GGTGGTCTC',\n",
    " 'F923': 'GCCTTAACC',\n",
    " 'F924': 'TATTAACTG',\n",
    " 'F925': 'TGGCCTGTG',\n",
    " 'F926': 'TGGCCGTCA',\n",
    " 'F927': 'AGCAAGGTC',\n",
    " 'F928': 'ACTCAATCT',\n",
    " 'F929': 'TGGACTCCT',\n",
    " 'F930': 'TGCTATCGC',\n",
    " 'F931': 'ACCTTGCCA',\n",
    " 'F932': 'TATGCTATG',\n",
    " 'F933': 'ACGACTTGG',\n",
    " 'F934': 'GCAGATGCA',\n",
    " 'F935': 'TAACGCGTC',\n",
    " 'F936': 'AAGTAGGCT',\n",
    " 'F937': 'TCTAACCAT',\n",
    " 'F938': 'ATACGCAGC',\n",
    " 'F939': 'GCCGTTACA',\n",
    " 'F940': 'GCACCTATT',\n",
    " 'F941': 'GATTGTGTT',\n",
    " 'F942': 'ATACCGGCA',\n",
    " 'F943': 'CGTAACTTA',\n",
    " 'F944': 'GGTCTAGCT',\n",
    " 'F945': 'AGACACAAT',\n",
    " 'F946': 'TTGACGCTA',\n",
    " 'F947': 'ATGCTCACA',\n",
    " 'F948': 'TAGGTTCTG',\n",
    " 'F949': 'AAGTCCTAA',\n",
    " 'F950': 'GAGCATGGC',\n",
    " 'F951': 'GAACTGTAT',\n",
    " 'F952': 'AAGCGTATA',\n",
    " 'F953': 'TGAATCCAA',\n",
    " 'F954': 'GAACATCGG',\n",
    " 'F955': 'GCCACCGAA',\n",
    " 'F956': 'GTGATCTGA',\n",
    " 'F957': 'TTGTGCTAT',\n",
    " 'F958': 'GCGTAGCGA',\n",
    " 'F959': 'AACCAGAGG',\n",
    " 'F960': 'GCGTGAGGA',\n",
    " 'F961': 'TACCTCTCG',\n",
    " 'F962': 'AATGACAGA',\n",
    " 'F963': 'AGACTGGCG',\n",
    " 'F964': 'GTTGTAGCG'}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Starting variables required from the function\n",
    "mapped_plate = pd.DataFrame.from_dict(plate_wells_mapping)\n",
    "flavours_list = flavours_list\n",
    "\n",
    "r_primers_to_sequence = r_primers_to_sequence\n",
    "\n",
    "f_primers_to_sequence=f_primers_to_sequence\n",
    "\n",
    "f_primers_to_reverse_complement = f_primers_to_reverse_complement\n",
    "\n",
    "\n",
    "# Function takes in the DF from ONE SINGLE table as well as the flavour\n",
    "to_map = to_map\n",
    "flavour = 'I'\n",
    "\n",
    "# to_map, mapped_plate, flavour\n",
    "\n",
    "\n",
    "#### Need to add check if the machine is the nextseq\n",
    "\n",
    "def map_plate(to_map, flavour, next_seq=False, mini_seq=False):\n",
    "    # Mapped_plate is a constant, flavour changes for 24 and 48 to 24/48-Well\n",
    "    df = pd.DataFrame({'Sample_Name':to_map.values.ravel(), 'Sample_Well': mapped_plate.values.ravel()})\n",
    "    df['Sample_Plate'] = flavour \n",
    "\n",
    "    #OTHER CHECKS?? IF BLANK REMOVE? !!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "    # Add indexes from dictionaries\n",
    "    indexes_flavours = flavours_list[flavour]\n",
    "    df['I5_Index_ID'] = df['Sample_Well'].apply(lambda x: indexes_flavours[x][0])\n",
    "    df['I7_Index_ID'] = df['Sample_Well'].apply(lambda x: indexes_flavours[x][1])\n",
    "\n",
    "    #Map sequences from index name\n",
    "    # df['I5_Index_ID'] = df['Sample_Well'].map(indexes_flavours)\n",
    "\n",
    "    df['index'] = df['I7_Index_ID'].map(r_primers_to_sequence)\n",
    "\n",
    "    #If next seq map to other dict\n",
    "    if next_seq:\n",
    "        df['index2'] = df['I5_Index_ID'].map(f_primers_to_reverse_complement)\n",
    "    else:\n",
    "        df['index2'] = df['I5_Index_ID'].map(f_primers_to_sequence)\n",
    "\n",
    "    # Add Sample_Project and Description rows (empty rows)\n",
    "    df['Sample_Project'], df['Description']  = np.nan, np.nan\n",
    "    \n",
    "    # Add Sample_ID (eg row index, but with index 1 instead of 0)\n",
    "    df['Sample_ID'] = df.index +1\n",
    "\n",
    "    if mini_seq:\n",
    "        df = df[['Sample_ID', 'Description', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project']]\n",
    "    else:\n",
    "        df = df[['Sample_ID', 'Sample_Name', 'Sample_Plate', 'Sample_Well', 'I7_Index_ID', 'index', 'I5_Index_ID', 'index2', 'Sample_Project', 'Description']]\n",
    "\n",
    "    return df\n",
    "\n",
    "map_plate(to_map, flavour) # Add kwargs next_seq/mini_seq if required\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_table(table):\n",
    "    cells = list(table.values.ravel())\n",
    "    blanks = 0\n",
    "    pos_controls = 0\n",
    "    neg_controls = 0\n",
    "    # Regular expression extracts all cells that start with one or more underscores and are not positive or negative controls\n",
    "    to_change = []\n",
    "    for cell in list(cells):\n",
    "        # Check for regex\n",
    "        match = re.findall(r'(_+(?!bsnc|bspc)\\w+)', cell)\n",
    "        if match:\n",
    "            print('HEY ', cell ,match)\n",
    "            cells.remove(cell)\n",
    "            to_change.append(match[0])\n",
    "\n",
    "        #Check if blank\n",
    "        if cell == 'blank':\n",
    "            cells.remove(cell)\n",
    "            blanks +=1 \n",
    "\n",
    "        #Check if pos control\n",
    "        if cell == '_bspc':\n",
    "            cells.remove(cell)\n",
    "            pos_controls +=1 \n",
    "\n",
    "        #Check if neg control\n",
    "        if cell == '_bsnc':\n",
    "            cells.remove(cell)\n",
    "            neg_controls +=1 \n",
    "\n",
    "    total_samples=len(cells)\n",
    "    unique_sample_names=len(set(cells))\n",
    "    something_wrong = len(to_change) > 0 or total_samples != unique_sample_names\n",
    "    \n",
    "    specs = dict(blanks = blanks, positive_controls = pos_controls, negative_controls=neg_controls, to_change = to_change, total_samples=total_samples, unique_sample_names=unique_sample_names, something_wrong=something_wrong)\n",
    "    return specs\n",
    "\n",
    "\n",
    "print(check_table(test_tables[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW APPEND THIS BELOW HEADER AND YOURE DONE; NEED TO IMPLEMENT CHECKS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_map.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mapped_plate.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_methods(object, spacing=20):\n",
    "  methodList = []\n",
    "  for method_name in dir(object):\n",
    "    try:\n",
    "        if callable(getattr(object, method_name)):\n",
    "            methodList.append(str(method_name))\n",
    "    except Exception:\n",
    "        methodList.append(str(method_name))\n",
    "  processFunc = (lambda s: ' '.join(s.split())) or (lambda s: s)\n",
    "  for method in methodList:\n",
    "    try:\n",
    "        print(str(method.ljust(spacing)) + ' ' +\n",
    "              processFunc(str(getattr(object, method).__doc__)[0:90]))\n",
    "    except Exception:\n",
    "        print(method.ljust(spacing) + ' ' + ' getattr() failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
